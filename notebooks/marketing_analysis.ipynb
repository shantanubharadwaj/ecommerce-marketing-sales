{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ee2f22",
   "metadata": {},
   "source": [
    "# E-commerce Marketing and Sales Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15757960",
   "metadata": {},
   "source": [
    "### 1. Business Context and Problem \n",
    "\n",
    "The objective of this project is to leverage data-driven insights to enhance customer acquisition, retention, and optimize revenue streams for an e-commerce company.\n",
    "\n",
    "The focus areas include analyzing transactions, marketing spends, discount strategies, customer behavior, and product performance across a complete calendar year.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Through exploratory analysis and visualization, we aim to answer key business questions such as:\n",
    "\n",
    "- Identify months with highest and lowest customer acquisition.\n",
    "- Analyze retention patterns and customer lifetime value.\n",
    "- Evaluate coupon effectiveness and marketing ROI.\n",
    "- Segment customers using RFM analysis to tailor strategies.\n",
    "- Understand how taxes and delivery charges influence purchasing behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fb1d4",
   "metadata": {},
   "source": [
    "### 2. Data Description\n",
    "\n",
    "The project utilizes multiple datasets covering the period 1st Jan 2019 to 31st Dec 2019:\n",
    "\n",
    "- Online Sales: Transaction-level sales data including quantity, pricing, and product details.\n",
    "- Customers Data: Customer demographic information such as gender, location, and tenure.\n",
    "- Discount Coupons: Information on discount codes and associated percentages across months and categories.\n",
    "- Marketing Spend: Daily spend data across offline and online marketing channels.\n",
    "- Tax Amount: GST percentages applicable by product categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d450b92",
   "metadata": {},
   "source": [
    "### 3. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52717e49",
   "metadata": {},
   "source": [
    "### 4. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../resources/Online_Sales.csv')\n",
    "customers = pd.read_excel('../resources/CustomersData.xlsx')\n",
    "discounts = pd.read_csv('../resources/Discount_Coupon.csv')\n",
    "marketing = pd.read_csv('../resources/Marketing_Spend.csv')\n",
    "tax = pd.read_excel('../resources/Tax_amount.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1e4c9",
   "metadata": {},
   "source": [
    "### 5. Data Overview and initial data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879855ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime object\n",
    "sales['Transaction_Date'] = pd.to_datetime(sales['Transaction_Date'])\n",
    "marketing['Date'] = pd.to_datetime(marketing['Date'])\n",
    "\n",
    "# Create new Month columns\n",
    "sales['Transaction_Month'] = sales['Transaction_Date'].dt.to_period('M')\n",
    "marketing['Marketing_Month'] = marketing['Date'].dt.to_period('M')\n",
    "\n",
    "# lower-casing all column names\n",
    "sales.columns = sales.columns.str.lower()\n",
    "customers.columns = customers.columns.str.lower()\n",
    "discounts.columns = discounts.columns.str.lower()\n",
    "marketing.columns = marketing.columns.str.lower()\n",
    "tax.columns = tax.columns.str.lower()\n",
    "\n",
    "# if all discounts are for 2019:\n",
    "discounts['month'] = pd.to_datetime('2019-' + discounts['month'], format='%Y-%b').dt.to_period('M')\n",
    "\n",
    "for df in (sales, discounts, tax):\n",
    "    df['product_category'] = df['product_category'].str.strip().str.lower()\n",
    "    \n",
    "sales.rename(columns={'customerid':'customer_id'}, inplace=True)\n",
    "customers.rename(columns={'customerid':'customer_id'}, inplace=True)\n",
    "\n",
    "sales['revenue'] = sales['quantity'] * sales['avg_price']\n",
    "sales['total_amount'] = sales['revenue'] + sales['delivery_charges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer integrity check\n",
    "# unique customers in sales\n",
    "sales_customers = set(sales['customer_id'].unique())\n",
    "\n",
    "# unique customers in customer\n",
    "customers_list = set(customers['customer_id'].unique())\n",
    "\n",
    "missing_customers = sales_customers - customers_list\n",
    "print(f\"No of customers in sales not found in customers table : {len(missing_customers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbaeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data\n",
    "sales.to_csv('../eda_outputs/sales_cleaned.csv', index=False)\n",
    "customers.to_csv('../eda_outputs/customers_cleaned.csv', index=False)\n",
    "discounts.to_csv('../eda_outputs/discounts_cleaned.csv', index=False)\n",
    "marketing.to_csv('../eda_outputs/marketing_cleaned.csv', index=False)\n",
    "tax.to_csv('../eda_outputs/tax_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fcd9c",
   "metadata": {},
   "source": [
    "## Question 1  \n",
    "**Identify the months with the highest and lowest acquisition rates.**  \n",
    "*What strategies could be implemented to address the fluctuations and ensure consistent growth throughout the year?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute each customer's first purchase month\n",
    "first_purchase = (\n",
    "    sales\n",
    "    .groupby('customer_id')['transaction_date']\n",
    "    .min()\n",
    "    .dt.to_period('M')\n",
    "    .rename('first_month')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Count new customers per month\n",
    "monthly_acquisition = (\n",
    "    first_purchase\n",
    "    .groupby('first_month')\n",
    "    .size()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Identify best and worst\n",
    "best_month  = monthly_acquisition.idxmax()\n",
    "best_count  = monthly_acquisition.max()\n",
    "worst_month = monthly_acquisition.idxmin()\n",
    "worst_count = monthly_acquisition.min()\n",
    "\n",
    "print(f\"Highest acquisition: {best_month} → {best_count} new customers\")\n",
    "print(f\"Lowest  acquisition: {worst_month} → {worst_count} new customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836fdf9e",
   "metadata": {},
   "source": [
    "### Results  \n",
    "**Highest acquisition month:** January, 2019 with 215 new customers  \n",
    "**Lowest acquisition month:** November with 68 new customers  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a816184",
   "metadata": {},
   "source": [
    "## Question 2  \n",
    "**Analyze the data to determine if certain months consistently show higher or lower acquisition rates.**  \n",
    "*How can the company capitalize on high-performing months and improve performance during slower periods?*\n",
    "\n",
    "### 2.1 Business Story & Context  \n",
    "> New-customer acquisition often follows a seasonal pattern.  \n",
    "> By quantifying which calendar months over- or under-perform, we can time campaigns, budget, and product launches to maximize ROI and smooth out revenue dips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_purchase2 = (\n",
    "    sales\n",
    "    .groupby('customer_id')['transaction_date']\n",
    "    .min()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Extract month name and order Jan→Dec\n",
    "first_purchase2['month'] = first_purchase2['transaction_date'].dt.month_name()\n",
    "month_order = [\n",
    "    \"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n",
    "    \"July\",\"August\",\"September\",\"October\",\"November\",\"December\"\n",
    "]\n",
    "\n",
    "# Count and assemble seasonality table\n",
    "monthly_acq_by_month = (\n",
    "    first_purchase2['month']\n",
    "    .value_counts()\n",
    "    .reindex(month_order)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "avg = monthly_acq_by_month.mean()\n",
    "deviation = (monthly_acq_by_month - avg) / avg * 100\n",
    "seasonality = pd.DataFrame({\n",
    "    'acquisitions': monthly_acq_by_month,\n",
    "    'pct_vs_avg': deviation.round(1)\n",
    "})\n",
    "sales.to_csv('../eda_outputs/acquisation_seasonality.csv', index=False)\n",
    "\n",
    "# Visualizations \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(seasonality.index, seasonality['acquisitions'])\n",
    "plt.title(\"New-Customer Acquisitions by Calendar Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of New Customers\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/acquisation_seasonality.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547683bf",
   "metadata": {},
   "source": [
    "## Question 3  \n",
    "**Identify periods with the strongest and weakest retention rates.**  \n",
    "*What strategies could be implemented to improve retention during weaker months?*\n",
    "\n",
    "### 3.1. Business Story & Context\n",
    "\n",
    "While acquisition brings in new customers, retention ensures long-term revenue and brand loyalty.\n",
    "Identifying strong and weak retention periods helps the business understand when customers tend to come back—and when they don’t—so that lifecycle campaigns and engagement strategies can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818af97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join first_month to sales\n",
    "sales_fp = sales.merge(first_purchase, on='customer_id')\n",
    "\n",
    "sales_fp['month'] = sales_fp['transaction_month']\n",
    "\n",
    "# customers who made purchases in the month after their first\n",
    "retention_flags = (\n",
    "    sales_fp[sales_fp['month'] > sales_fp['first_month']]\n",
    "    .assign(next_month = sales_fp['first_month'] + 1)\n",
    "    .query(\"month == next_month\")\n",
    "    .groupby('first_month')['customer_id']\n",
    "    .nunique()\n",
    "    .rename('retained')\n",
    ")\n",
    "\n",
    "# new customers in each month\n",
    "cohort_sizes = first_purchase.groupby('first_month')['customer_id'].nunique().rename('acquired')\n",
    "\n",
    "# Combine and calculate retention rate\n",
    "retention = pd.concat([cohort_sizes, retention_flags], axis=1).fillna(0)\n",
    "retention['retention_rate'] = (retention['retained'] / retention['acquired']).round(2)\n",
    "\n",
    "retention.to_csv('../eda_outputs/next_month_retention.csv', index=False)\n",
    "\n",
    "\n",
    "# Visualiazation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(retention.index.astype(str), retention['retention_rate'], marker='o')\n",
    "plt.title(\"Next-Month Customer Retention Rate by Acquisition Month\")\n",
    "plt.xlabel(\"Cohort (Acquisition) Month\")\n",
    "plt.ylabel(\"Retention Rate\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/next_month_retention.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5e972",
   "metadata": {},
   "source": [
    "### 3.2. Results\n",
    "\n",
    "Based on the **next-month retention** rates:\n",
    "\n",
    "| Cohort (Acq Month) | Retention Rate |\n",
    "|--------------------|----------------|\n",
    "| **Highest**        |                |\n",
    "| 2019-06            | 15 %           |\n",
    "| 2019-07            | 14 %           |\n",
    "| **Lowest**         |                |\n",
    "| 2019-01            |  6 %           |\n",
    "| 2019-02,10         |  7 %           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fefb7",
   "metadata": {},
   "source": [
    "## Question 4  \n",
    "**Analyze customer behavior during high-retention months and suggest ways to replicate this success throughout the year.**\n",
    "\n",
    "### 4.1. Business Story & Context  \n",
    "> Cohorts with strong retention often exhibit particular behaviors—higher AOV, smart coupon usage or favorite categories—that drive repeat purchases.  \n",
    "> By uncovering these patterns, we can design campaigns in slower months that mimic their success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-retention cohorts (≥ average retention rate)\n",
    "\n",
    "avg_ret = retention['retention_rate'].mean()\n",
    "high_retention_months = retention[retention['retention_rate'] >= avg_ret].index.tolist()\n",
    "\n",
    "\n",
    "# For each high-retention cohort, analyze next-month behavior\n",
    "behavior_list = []\n",
    "for cohort in high_retention_months:\n",
    "    custs = first_purchase[first_purchase['first_month'] == cohort]['customer_id']\n",
    "    next_mon = cohort + 1\n",
    "    df_next = sales[(sales['customer_id'].isin(custs)) & \n",
    "                    (sales['transaction_month'] == next_mon)]\n",
    "    behavior_list.append({\n",
    "        'cohort': str(cohort),\n",
    "        'avg_order_value': df_next['total_amount'].mean(),\n",
    "        'coupon_rate': (df_next['coupon_status']=='Used').mean(),\n",
    "        'top_categories': ', '.join(\n",
    "            df_next['product_category'].value_counts().head(3).index.tolist()\n",
    "        )\n",
    "    })\n",
    "\n",
    "behavior_df = pd.DataFrame(behavior_list).set_index('cohort')\n",
    "\n",
    "behavior_df.to_csv('../eda_outputs/retention_drivers.csv', index=False)\n",
    "\n",
    "# Visualizations \n",
    "# Avg Order Value for high-retention cohorts\n",
    "plt.figure(figsize=(8, 4))\n",
    "behavior_df['avg_order_value'].plot(kind='bar')\n",
    "plt.title('Avg Order Value in Next Month for High-Retention Cohorts')\n",
    "plt.ylabel('Avg Order Value')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/avg_order_value.png')\n",
    "plt.show()\n",
    "\n",
    "# Coupon Usage Rate for high-retention cohorts\n",
    "plt.figure(figsize=(8, 4))\n",
    "behavior_df['coupon_rate'].plot(kind='bar')\n",
    "plt.title('Coupon Usage Rate in Next Month for High-Retention Cohorts')\n",
    "plt.ylabel('Coupon Usage Rate')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/coupon_usage.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba2dfa",
   "metadata": {},
   "source": [
    "### 4.2 Results  \n",
    "\n",
    "| Cohort   | Avg Order Value ($) | Coupon Usage Rate | Top Categories                 |\n",
    "|----------|---------------------|-------------------|--------------------------------|\n",
    "| 2019-03  | 119.91              | 31.7%             | apparel, nest-usa, office      |\n",
    "| 2019-04  | 110.28              | 28.3%             | apparel, nest-usa, office      |\n",
    "| 2019-05  |  83.24              | 33.3%             | nest-usa, apparel, office      |\n",
    "| 2019-06  |  55.11              | 42.0%             | apparel, nest-usa, office      |\n",
    "| 2019-07  |  68.58              | 35.1%             | apparel, nest-usa, office      |\n",
    "| 2019-08  | 127.67              | 38.9%             | nest-usa, apparel, nest        |\n",
    "| 2019-11  | 153.00              | 36.4%             | nest-usa, nest, office         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e597e",
   "metadata": {},
   "source": [
    "## Question 5  \n",
    "**Compare the revenue generated by new and existing customers month-over-month.**  \n",
    "*What does this trend suggest about the balance between acquisition and retention efforts?*\n",
    "\n",
    "### 5.1 Business Story & Context  \n",
    "> Understanding how much revenue comes from **new** vs. **existing** customers each month reveals whether growth is driven more by acquisition or by repeat buying—and where to focus marketing and product efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e92b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotating each transaction as New vs. Existing\n",
    "sales_fp = sales.merge(first_purchase, on='customer_id')\n",
    "sales_fp['customer_type'] = np.where(\n",
    "    sales_fp['transaction_month'] == sales_fp['first_month'],\n",
    "    'new',\n",
    "    'existing'\n",
    ")\n",
    "\n",
    "# Aggregate monthly revenue by customer type\n",
    "monthly_revenue = (\n",
    "    sales_fp\n",
    "      .groupby(['transaction_month', 'customer_type'])['revenue']\n",
    "      .sum()\n",
    "      .unstack(fill_value=0)\n",
    "      .rename_axis(index='month')\n",
    ")\n",
    "\n",
    "# Compute total and % share\n",
    "monthly_revenue['total'] = monthly_revenue['new'] + monthly_revenue['existing']\n",
    "monthly_revenue['new_pct'] = (monthly_revenue['new'] / monthly_revenue['total'] * 100).round(1)\n",
    "monthly_revenue['existing_pct'] = (monthly_revenue['existing'] / monthly_revenue['total'] * 100).round(1)\n",
    "\n",
    "monthly_revenue.to_csv('../eda_outputs/revenue_new_existing.csv', index=False)\n",
    "\n",
    "# Visualizations  \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_revenue[['new', 'existing']].plot(kind='line', marker='o')\n",
    "plt.title(\"Monthly Revenue: New vs. Existing Customers\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Customer Type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/revenue_new_existing.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = monthly_revenue[['new_pct', 'existing_pct']].plot(kind='line', figsize=(10, 6), marker='o', title=\"Monthly Revenue %: New vs. Existing Customers\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Revenue (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "plt.legend(title=\"Customer Type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/revenue_new_existing_perc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b34ff",
   "metadata": {},
   "source": [
    "### 5.2 Results\n",
    "\n",
    "Based on the **new vs. existing revenue mix**:\n",
    "\n",
    "| Month    | New % | Existing % |\n",
    "|----------|-------|------------|\n",
    "| Jan – Mar | ≥ 84% | ≤ 16%     |\n",
    "| Apr – Jun | 58–64% | 36–42%   |\n",
    "| Jul – Sep | 40–48% | 52–60%   |\n",
    "| Oct – Dec | 42–53% | 47–58%   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0caddd",
   "metadata": {},
   "source": [
    "## Question 6  \n",
    "**Analyze the relationship between coupon usage and revenue generation.**  \n",
    "*How can discount strategies be optimized to maximize revenue while maintaining profitability?*\n",
    "\n",
    "### 6.1 Business Story & Context  \n",
    "> Coupons can drive traffic and sales, but heavy discounting can erode margins.  \n",
    "> By examining how different discount depths and coupon usage correlate with total and per-transaction revenue, we can identify the “sweet spot” for promotions that maximizes topline without sacrificing profitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sales with discounts to get the discount_pct for each transaction\n",
    "# discounts.month is a Period[M] matching sales.transaction_month\n",
    "sales_disc = (\n",
    "    sales\n",
    "    .merge(\n",
    "        discounts.assign(month=discounts['month'].astype('period[M]')),\n",
    "        left_on=['transaction_month', 'product_category'],\n",
    "        right_on=['month', 'product_category'],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fill missing discount_pct with 0 (no coupon offered)\n",
    "sales_disc['discount_pct'] = sales_disc['discount_pct'].fillna(0)\n",
    "\n",
    "# Compute “effective” discount only when coupon was used\n",
    "sales_disc['eff_discount_pct'] = np.where(\n",
    "    sales_disc['coupon_status'] == 'Used',\n",
    "    sales_disc['discount_pct'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Aggregate by discount bucket\n",
    "coupon_analysis = (\n",
    "    sales_disc\n",
    "    .groupby('eff_discount_pct')\n",
    "    .agg(\n",
    "        transactions=('transaction_id', 'count'),\n",
    "        total_revenue=('revenue', 'sum'),\n",
    "        avg_revenue=('revenue', 'mean')\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Compute share of total revenue\n",
    "coupon_analysis['rev_share_pct'] = (\n",
    "    coupon_analysis['total_revenue'] \n",
    "    / coupon_analysis['total_revenue'].sum() \n",
    "    * 100\n",
    ").round(1)\n",
    "\n",
    "coupon_analysis.to_csv('../eda_outputs/coupon_vs_revenue.csv', index=False)\n",
    "\n",
    "# Revenue share by discount depth\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(\n",
    "    coupon_analysis.index.astype(str),\n",
    "    coupon_analysis['rev_share_pct']\n",
    ")\n",
    "plt.title('Share of Total Revenue by Discount %')\n",
    "plt.xlabel('Effective Discount %')\n",
    "plt.ylabel('Revenue Share (%)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/coupon_vs_revenue_perc.png')\n",
    "plt.show()\n",
    "\n",
    "# Avg transaction revenue by discount depth\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(\n",
    "    coupon_analysis.index.astype(str),\n",
    "    coupon_analysis['avg_revenue']\n",
    ")\n",
    "plt.title('Avg Order Revenue by Discount %')\n",
    "plt.xlabel('Effective Discount %')\n",
    "plt.ylabel('Avg Revenue ($)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/discount_avg_revenue.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bb1b1",
   "metadata": {},
   "source": [
    "### 6.2 Results  \n",
    "\n",
    "| Discount % | Transactions | Total Revenue ($) | Avg Revenue ($) | Rev. Share (%) |\n",
    "|------------|--------------|-------------------|-----------------|----------------|\n",
    "| 0%         | 35,146       | 3,118,390.44      | 88.73           | 66.8           |\n",
    "| 10%        | 5,933        |   519,420.52      | 87.55           | 11.1           |\n",
    "| 20%        | 6,000        |   510,646.92      | 85.11           | 10.9           |\n",
    "| 30%        | 5,845        |   522,336.74      | 89.36           | 11.2           |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2738b",
   "metadata": {},
   "source": [
    "## Question 7  \n",
    "**Identify the top-performing products and analyze the factors driving their success.**  \n",
    "*How can this insight inform inventory management and promotional strategies?*\n",
    "\n",
    "### 7.1 Business Story & Context  \n",
    "> A small subset of SKUs often drives a large share of revenue and demand.  \n",
    "> By pinpointing which products sell the most (and why—e.g., price point, coupon use, category), you can optimize stock levels, prioritize high-ROI promotions, and avoid overstock or stock-outs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse sales_disc from Q6 (sales merged with discounts + eff_discount_pct)\n",
    "# If sales_disc is not in scope, recreate it:\n",
    "sales_disc = (\n",
    "    sales\n",
    "    .merge(\n",
    "        discounts.assign(month=discounts['month'].astype('period[M]')),\n",
    "        left_on=['transaction_month', 'product_category'],\n",
    "        right_on=['month','product_category'],\n",
    "        how='left'\n",
    "    )\n",
    "    .assign(\n",
    "        discount_pct=lambda df: df['discount_pct'].fillna(0),\n",
    "        eff_discount_pct=lambda df: (df['discount_pct'].where(df['coupon_status']=='Used', 0))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute per-product metrics\n",
    "product_metrics = (\n",
    "    sales_disc\n",
    "    .groupby(['product_sku','product_description','product_category'])\n",
    "    .agg(\n",
    "        total_revenue=('revenue','sum'),\n",
    "        total_units_sold=('quantity','sum'),\n",
    "        avg_price=('avg_price','mean'),\n",
    "        coupon_rate=('coupon_status', lambda x: (x=='Used').mean()),\n",
    "        avg_eff_discount=('eff_discount_pct','mean')\n",
    "    )\n",
    "    .sort_values('total_revenue', ascending=False)\n",
    ")\n",
    "\n",
    "# Select top 10 products by revenue\n",
    "top_products = product_metrics.head(10).round({\n",
    "    'total_revenue': 2,\n",
    "    'avg_price': 2,\n",
    "    'coupon_rate': 3,\n",
    "    'avg_eff_discount': 1\n",
    "})\n",
    "\n",
    "top_products.to_csv('../eda_outputs/top_products.csv', index=False)\n",
    "\n",
    "# Visualizations: Top 10 products by revenue\n",
    "by_sku = top_products.copy()\n",
    "by_sku.index = by_sku.index.get_level_values('product_sku')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "by_sku['total_revenue'].plot(\n",
    "    kind='bar',\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Top 10 Products by Total Revenue\")\n",
    "plt.xlabel(\"Product SKU\")\n",
    "plt.ylabel(\"Total Revenue ($)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/top_products.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f6c3d",
   "metadata": {},
   "source": [
    "### Results : (Top 5 products)\n",
    "\n",
    "| Product SKU       | Description                                               | Category | Total Rev ($) | Units Sold | Avg Price ($) | Coupon Rate | Avg Disc (%) |\n",
    "|-------------------|-----------------------------------------------------------|----------|---------------|------------|---------------|-------------|--------------|\n",
    "| GGOENEBJ079499    | Nest Learning Thermostat 3rd Gen-USA – Stainless Steel    | nest-usa |   688,916.34  | 4,570      | 150.98        | 34.3%       | 6.8%         |\n",
    "| GGOENEBQ078999    | Nest Cam Outdoor Security Camera – USA                    | nest-usa |   629,977.12  | 5,206      | 121.81        | 32.8%       | 6.5%         |\n",
    "| GGOENEBB078899    | Nest Cam Indoor Security Camera – USA                     | nest-usa |   528,612.93  | 4,402      | 120.21        | 32.0%       | 6.3%         |\n",
    "| GGOENEBQ079099    | Nest Protect Smoke + CO White Battery Alarm-USA          | nest-usa |   213,819.16  | 2,683      | 79.84         | 33.8%       | 6.4%         |\n",
    "| GGOENEBQ079199    | Nest Protect Smoke + CO White Wired Alarm-USA           | nest-usa |   212,495.57  | 2,670      | 79.75         | 37.0%       | 7.2%         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbac6d7",
   "metadata": {},
   "source": [
    "## Question 8  \n",
    "**Analyze the relationship between monthly marketing spend and revenue.**  \n",
    "*Are there any months where marketing efforts yielded disproportionately high or low returns? How can marketing strategies be adjusted to improve ROI?*\n",
    "\n",
    "### 8.1 Business Story & Context  \n",
    "> Every rupee spent on marketing should generate more than a rupee in revenue.  \n",
    "> By comparing monthly marketing spend (online + offline) against revenue, and computing an ROI metric, we can spot months of over- or under-performance and reallocate budget for maximum impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate monthly marketing spend\n",
    "monthly_spend = (\n",
    "    marketing\n",
    "    .groupby('marketing_month')\n",
    "    .agg(\n",
    "        offline_spend=('offline_spend', 'sum'),\n",
    "        online_spend=('online_spend', 'sum')\n",
    "    )\n",
    "    .assign(\n",
    "        total_spend=lambda df: df['offline_spend'] + df['online_spend']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine with our monthly revenue\n",
    "# monthly_revenue['total'] holds total revenue by transaction_month\n",
    "promo_df = (\n",
    "    monthly_spend\n",
    "    .merge(\n",
    "        monthly_revenue['total'].rename('revenue'),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute simple ROI = revenue / total_spend\n",
    "promo_df['roi'] = (promo_df['revenue'] / promo_df['total_spend']).round(2)\n",
    "\n",
    "promo_df.to_csv('../eda_outputs/marketing_roi.csv', index=False)\n",
    "\n",
    "# Visualizations  \n",
    "\n",
    "# Revenue vs. Marketing Spend scatter\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    promo_df['total_spend'],\n",
    "    promo_df['revenue']\n",
    ")\n",
    "plt.title(\"Revenue vs. Total Marketing Spend by Month\")\n",
    "plt.xlabel(\"Total Marketing Spend ($)\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/marketing_roi.png')\n",
    "plt.show()\n",
    "\n",
    "# ROI by Month bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "promo_df['roi'].plot(kind='bar', legend=False)\n",
    "plt.title(\"Monthly Marketing ROI (Revenue ÷ Spend)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"ROI\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/marketing_roi_monthly.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15c1a6",
   "metadata": {},
   "source": [
    "### 8.2 Results  \n",
    "\n",
    "| Month    | Offline Spend ($) | Online Spend ($) | Total Spend ($) | Revenue ($)  | ROI  |\n",
    "|----------|-------------------|------------------|-----------------|--------------|------|\n",
    "| 2019-01  | 96,600            | 58,328.95        | 154,928.95      | 403,624.58   | 2.61 |\n",
    "| 2019-02  | 81,300            | 55,807.92        | 137,107.92      | 310,819.80   | 2.27 |\n",
    "| 2019-03  | 73,500            | 48,750.09        | 122,250.09      | 349,608.09   | 2.86 |\n",
    "| 2019-04  | 96,000            | 61,026.83        | 157,026.83      | 401,618.42   | 2.56 |\n",
    "| 2019-05  | 65,500            | 52,759.64        | 118,259.64      | 307,763.42   | 2.60 |\n",
    "| 2019-06  | 80,500            | 53,818.14        | 134,318.14      | 321,081.38   | 2.39 |\n",
    "| 2019-07  | 67,500            | 52,717.85        | 120,217.85      | 372,638.07   | 3.10 |\n",
    "| 2019-08  | 85,500            | 57,404.15        | 142,904.15      | 401,210.37   | 2.81 |\n",
    "| 2019-09  | 83,000            | 52,514.54        | 135,514.54      | 360,548.40   | 2.66 |\n",
    "| 2019-10  | 93,500            | 57,724.65        | 151,224.65      | 409,681.28   | 2.71 |\n",
    "| 2019-11  | 93,000            | 68,144.96        | 161,144.96      | 508,942.62   | 3.16 |\n",
    "| 2019-12  | 122,000           | 76,648.75        | 198,648.75      | 523,258.19   | 2.63 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c43c0",
   "metadata": {},
   "source": [
    "## Question 9  \n",
    "**Evaluate the effectiveness of marketing campaigns by comparing marketing spend to revenue generated.**  \n",
    "*Are there opportunities to reallocate resources for better results?*\n",
    "\n",
    "### 9.1 Business Story & Context  \n",
    "> Assessing which channels deliver the best return allows us to shift budgets away from under-performing tactics into high-ROI campaigns—maximizing impact per rupee spent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROI by channel\n",
    "channel_roi = promo_df.copy().assign(\n",
    "    roi_offline=lambda df: (df['revenue'] / df['offline_spend']).round(2),\n",
    "    roi_online =lambda df: (df['revenue'] / df['online_spend']).round(2)\n",
    ")[[\n",
    "    'offline_spend','online_spend','revenue','roi_offline','roi_online'\n",
    "]]\n",
    "\n",
    "channel_roi.to_csv('../eda_outputs/channel_roi.csv', index=False)\n",
    "\n",
    "# Visualizations  \n",
    "# Side-by-side ROI comparison\n",
    "ax = channel_roi[['roi_offline','roi_online']].plot(\n",
    "    kind='bar', figsize=(10, 6), rot=45\n",
    ")\n",
    "ax.set_title(\"Monthly ROI: Offline vs. Online Marketing\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"ROI (Revenue ÷ Spend)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/channel_roi.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7be52",
   "metadata": {},
   "source": [
    "### 9.2. Results  \n",
    "\n",
    "| Month    | Offline Spend ($) | Online Spend ($) | Total Spend ($) | Revenue ($)  | Offline ROI | Online ROI |\n",
    "|----------|-------------------|------------------|-----------------|--------------|-------------|------------|\n",
    "| 2019-01  | 96,600            | 58,328.95        | 154,928.95      | 403,624.58   | 4.18×       | 6.92×      |\n",
    "| 2019-02  | 81,300            | 55,807.92        | 137,107.92      | 310,819.80   | 3.82×       | 5.57×      |\n",
    "| 2019-03  | 73,500            | 48,750.09        | 122,250.09      | 349,608.09   | 4.76×       | 7.17×      |\n",
    "| 2019-04  | 96,000            | 61,026.83        | 157,026.83      | 401,618.42   | 4.18×       | 6.58×      |\n",
    "| 2019-05  | 65,500            | 52,759.64        | 118,259.64      | 307,763.42   | 4.70×       | 5.83×      |\n",
    "| 2019-06  | 80,500            | 53,818.14        | 134,318.14      | 321,081.38   | 3.99×       | 5.97×      |\n",
    "| 2019-07  | 67,500            | 52,717.85        | 120,217.85      | 372,638.07   | 5.52×       | 7.07×      |\n",
    "| 2019-08  | 85,500            | 57,404.15        | 142,904.15      | 401,210.37   | 4.69×       | 6.99×      |\n",
    "| 2019-09  | 83,000            | 52,514.54        | 135,514.54      | 360,548.40   | 4.34×       | 6.87×      |\n",
    "| 2019-10  | 93,500            | 57,724.65        | 151,224.65      | 409,681.28   | 4.38×       | 7.10×      |\n",
    "| 2019-11  | 93,000            | 68,144.96        | 161,144.96      | 508,942.62   | 5.47×       | 7.47×      |\n",
    "| 2019-12  | 122,000           | 76,648.75        | 198,648.75      | 523,258.19   | 4.29×       | 6.83×      |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00913fbd",
   "metadata": {},
   "source": [
    "## Question 10  \n",
    "**Segment customers into groups such as Premium, Gold, Silver, and Standard using RFM techniques.**  \n",
    "*What targeted strategies can be developed for each segment to improve retention and revenue?*\n",
    "\n",
    "### 10.1 Business Story & Context  \n",
    "> Not all customers are alike—some buy often and spend big, others rarely return.  \n",
    "> **RFM segmentation** (Recency, Frequency, Monetary) lets us tailor retention and upsell strategies to each group, maximizing ROI on marketing and loyalty investments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48100593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RFM metrics\n",
    "# Use the latest transaction date as reference\n",
    "last_date = sales['transaction_date'].max()\n",
    "\n",
    "# Build a table of customer-level RFM\n",
    "rfm = sales.groupby('customer_id').agg(\n",
    "    recency_days=('transaction_date', lambda x: (last_date - x.max()).days),\n",
    "    frequency=('transaction_id', 'nunique'),\n",
    "    monetary=('revenue', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Define quartiles for scoring\n",
    "quantiles = rfm[['recency_days','frequency','monetary']].quantile([0.25,0.50,0.75]).to_dict()\n",
    "\n",
    "# Score each metric on a 1–4 scale\n",
    "def r_score(x):\n",
    "    if x <= quantiles['recency_days'][0.25]: return 4\n",
    "    if x <= quantiles['recency_days'][0.50]: return 3\n",
    "    if x <= quantiles['recency_days'][0.75]: return 2\n",
    "    return 1\n",
    "\n",
    "def fm_score(x, col):\n",
    "    if x <= quantiles[col][0.25]: return 1\n",
    "    if x <= quantiles[col][0.50]: return 2\n",
    "    if x <= quantiles[col][0.75]: return 3\n",
    "    return 4\n",
    "\n",
    "rfm['R_score'] = rfm['recency_days'].apply(r_score)\n",
    "rfm['F_score'] = rfm['frequency'].apply(lambda x: fm_score(x, 'frequency'))\n",
    "rfm['M_score'] = rfm['monetary'].apply(lambda x: fm_score(x, 'monetary'))\n",
    "\n",
    "# Combine into segments\n",
    "# Premium if all scores ≥3, Gold if all ≥2, Silver if sum ≥5, else Standard\n",
    "rfm['segment'] = 'Standard'\n",
    "rfm.loc[(rfm[['R_score','F_score','M_score']] >= 3).all(axis=1), 'segment'] = 'Premium'\n",
    "rfm.loc[\n",
    "    (rfm[['R_score','F_score','M_score']] >= 2).all(axis=1) & \n",
    "    (rfm['segment'] != 'Premium'),\n",
    "    'segment'\n",
    "] = 'Gold'\n",
    "rfm.loc[\n",
    "    (rfm['segment']=='Standard') & (rfm[['R_score','F_score','M_score']].sum(axis=1) >= 5),\n",
    "    'segment'\n",
    "] = 'Silver'\n",
    "\n",
    "# Inspect segment distribution\n",
    "segment_counts = rfm['segment'].value_counts().rename_axis('segment').reset_index(name='count')\n",
    "\n",
    "segment_counts.to_csv('../eda_outputs/segment_counts.csv', index=False)\n",
    "\n",
    "\n",
    "#Visualizations \n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(segment_counts['segment'], segment_counts['count'])\n",
    "plt.title(\"Customer Count by RFM Segment\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/segment_counts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cdd03",
   "metadata": {},
   "source": [
    "### 10.2 Results  \n",
    "\n",
    "**Sample RFM table (first 5 customers):**\n",
    "\n",
    "| customer_id | recency_days | frequency | monetary   | R_score | F_score | M_score | segment  |\n",
    "|-------------|--------------|-----------|------------|---------|---------|---------|----------|\n",
    "| 12346       | 107          | 1         | $30.99     | 3       | 1       | 1       | Silver   |\n",
    "| 12347       | 59           | 31        | $13,834.90 | 3       | 4       | 4       | Premium  |\n",
    "| 12348       | 73           | 8         | $1,442.12  | 3       | 2       | 2       | Gold     |\n",
    "| 12350       | 17           | 11        | $1,360.07  | 4       | 2       | 2       | Gold     |\n",
    "| 12356       | 107          | 13        | $1,442.47  | 3       | 3       | 2       | Gold     |\n",
    "\n",
    "**Segment distribution:**\n",
    "\n",
    "| Segment   | Count |\n",
    "|-----------|-------|\n",
    "| Premium   | 417   |\n",
    "| Silver    | 406   |\n",
    "| Gold      | 384   |\n",
    "| Standard  | 261   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afb823",
   "metadata": {},
   "source": [
    "## Question 11  \n",
    "**Analyze the revenue contribution of each customer segment.**  \n",
    "*How can the company focus its efforts on high-value segments while nurturing lower-value segments?*\n",
    "\n",
    "### 11.1 Business Story & Context  \n",
    "> Understanding which RFM segments drive the most revenue informs where to double down with premium service and where to invest in growth programs.  \n",
    "> We’ll quantify each segment’s share of total revenue and average spend per customer to guide resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate revenue by segment\n",
    "segment_rev = (\n",
    "    rfm\n",
    "    .groupby('segment')['monetary']\n",
    "    .agg(\n",
    "        total_revenue=('sum'),\n",
    "        avg_revenue=('mean'),\n",
    "        customer_count=('count')\n",
    "    )\n",
    "    .assign(\n",
    "        rev_share_pct=lambda df: (df['total_revenue'] / df['total_revenue'].sum() * 100).round(1)\n",
    "    )\n",
    "    .sort_values('total_revenue', ascending=False)\n",
    ")\n",
    "\n",
    "segment_rev.to_csv('../eda_outputs/segment_rev.csv', index=False)\n",
    "\n",
    "# Visualizations  \n",
    "# Revenue share by segment\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(segment_rev.index, segment_rev['rev_share_pct'])\n",
    "plt.title(\"Revenue Share by Customer Segment\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Revenue Share (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/segment_rev_cust.png')\n",
    "plt.show()\n",
    "\n",
    "# Avg revenue per customer by segment\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(segment_rev.index, segment_rev['avg_revenue'])\n",
    "plt.title(\"Average Revenue per Customer by Segment\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Avg Spend ($)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/avg_segment_rev.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f4bfe",
   "metadata": {},
   "source": [
    "### 11.2 Results  \n",
    "\n",
    "| Segment   | Customer Count | Total Revenue ($) | % of Total Rev | Avg Revenue per Cust ($) |\n",
    "|-----------|----------------|-------------------|----------------|--------------------------|\n",
    "| **Premium**   | 417            | 2,868,407.74      | 61.4 %         | 6,878.68                 |\n",
    "| **Gold**      | 384            |   905,958.68      | 19.4 %         | 2,359.27                 |\n",
    "| **Silver**    | 406            |   806,899.87      | 17.3 %         | 1,987.44                 |\n",
    "| **Standard**  | 261            |    89,528.33      |  1.9 %         |   343.02                 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1402e6c",
   "metadata": {},
   "source": [
    "## Question 12  \n",
    "**Group customers by their month of first purchase and analyze retention rates over time.**  \n",
    "*Which cohorts exhibit the highest and lowest retention rates? What strategies can be implemented to improve retention for weaker cohorts?*\n",
    "\n",
    "### 12.1 Business Story & Context  \n",
    "> By tracking each “first-purchase month” cohort’s repeat behavior over subsequent months, we can see which acquisition periods produce the stickiest customers—and where to shore up our lifecycle programs to reduce churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique customer counts by cohort and transaction month\n",
    "cohort = (\n",
    "    sales\n",
    "    .merge(first_purchase, on='customer_id')\n",
    "    .groupby(['first_month','transaction_month'])['customer_id']\n",
    "    .nunique()\n",
    "    .reset_index(name='n_customers')\n",
    ")\n",
    "\n",
    "# Compute period number: months since first purchase\n",
    "cohort['period_number'] = (cohort['transaction_month'] - cohort['first_month']).apply(lambda x: x.n)\n",
    "\n",
    "# Pivot into a retention matrix (including period 0 = cohort size)\n",
    "cohort_pivot = cohort.pivot(\n",
    "    index='first_month',\n",
    "    columns='period_number',\n",
    "    values='n_customers'\n",
    ").fillna(0)\n",
    "\n",
    "# Compute retention rates by dividing by cohort size (period 0)\n",
    "retention_table = (\n",
    "    cohort_pivot\n",
    "    .div(cohort_pivot[0], axis=0)\n",
    "    .drop(columns=0)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "retention_table.to_csv('../eda_outputs/retention_rates.csv', index=False)\n",
    "\n",
    "# Visualizations  \n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(retention_table, annot=True, fmt='.0%', cmap='YlGnBu')\n",
    "plt.title('Cohort Retention Matrix')\n",
    "plt.xlabel('Months Since Acquisition')\n",
    "plt.ylabel('Acquisition Month')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/cohort_retention.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47949214",
   "metadata": {},
   "source": [
    "### 12.2 Results  \n",
    "\n",
    "| Cohort   | 1 mo | 2 mo | 3 mo | 4 mo | 5 mo | 6 mo |\n",
    "|----------|------|------|------|------|------|------|\n",
    "| **2019-01** |  6 % | 11 % | 16 % | 11 % | 20 % | 16 % |\n",
    "| **2019-02** |  7 % |  9 % | 17 % | 18 % | 23 % | 20 % |\n",
    "| **2019-03** | 10 % | 20 % | 14 % | 18 % | 19 % | 12 % |\n",
    "| **2019-04** |  9 % | 15 % | 15 % | 11 % |  9 % |  6 % |\n",
    "| **2019-05** | 11 % |  8 % | 12 % |  9 % | 12 % | 12 % |\n",
    "| **2019-06** | 15 % | 16 % |  9 % |  8 % | 10 % |  8 % |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c82882",
   "metadata": {},
   "source": [
    "## Question 13  \n",
    "**Analyze the lifetime value of customers acquired in different months.**  \n",
    "*How can this insight inform acquisition and retention strategies?*\n",
    "\n",
    "\n",
    "### 13.1 Business Story & Context  \n",
    "> Lifetime Value (LTV) measures the total revenue a customer generates over their entire relationship.  \n",
    "> Comparing cohort LTV by acquisition month reveals which marketing windows yield the most valuable customers—and where to fine-tune spend and nurture tactics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total revenue per customer (their lifetime value)\n",
    "ltv_per_customer = (\n",
    "    sales\n",
    "    .groupby('customer_id')['revenue']\n",
    "    .sum()\n",
    "    .rename('ltv')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge LTV back to their cohort month\n",
    "ltv_cohort = (\n",
    "    first_purchase\n",
    "    .merge(ltv_per_customer, on='customer_id')\n",
    "    .groupby('first_month')\n",
    "    .agg(\n",
    "        cohort_size=('customer_id', 'nunique'),\n",
    "        total_ltv=('ltv', 'sum'),\n",
    "        avg_ltv=('ltv', 'mean')\n",
    "    )\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ltv_cohort.to_csv('../eda_outputs/ltv_cohort.csv', index=False)\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ltv_cohort['first_month'].astype(str), ltv_cohort['avg_ltv'], marker='o')\n",
    "plt.title(\"Average Customer LTV by Acquisition Month\")\n",
    "plt.xlabel(\"Acquisition Month\")\n",
    "plt.ylabel(\"Avg LTV ($)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/ltv_cohort.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a451c0",
   "metadata": {},
   "source": [
    "### 13.2 Results  \n",
    "\n",
    "| Cohort   | Cohort Size | Total LTV ($) | Avg LTV per Customer ($) |\n",
    "|----------|-------------|---------------|---------------------------|\n",
    "| **2019-01** | 215         | 1,037,320.06  | 4,824.74                  |\n",
    "| **2019-02** | 96          |   540,338.52  | 5,628.53                  |\n",
    "| **2019-03** | 177         |   668,895.39  | 3,779.07                  |\n",
    "| **2019-04** | 163         |   449,331.26  | 2,756.63                  |\n",
    "| **2019-05** | 112         |   332,698.60  | 2,970.52                  |\n",
    "| **2019-06** | 137         |   292,800.81  | 2,137.23                  |\n",
    "| **2019-07** | 94          |   240,255.54  | 2,555.91                  |\n",
    "| **2019-08** | 135         |   259,011.87  | 1,918.61                  |\n",
    "| **2019-09** | 78          |   151,664.24  | 1,944.41                  |\n",
    "| **2019-10** | 87          |   229,976.73  | 2,643.41                  |\n",
    "| **2019-11** | 68          |   221,691.63  | 3,260.17                  |\n",
    "| **2019-12** | 106         |   246,809.97  | 2,328.40                  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23592715",
   "metadata": {},
   "source": [
    "## Question 14  \n",
    "**Do customers who use coupons have a different average transaction value compared to those who do not?**  \n",
    "*Conduct a statistical test to validate this hypothesis. What implications does this have for the company’s discount and coupon strategies?*\n",
    "\n",
    "### 14.1 Business Story & Context  \n",
    "> Coupons are a powerful lever to drive sales volume, but they also carry margin risk if coupon-users consistently spend less per order.  \n",
    "> By comparing average transaction values for “coupon used” vs. “no coupon” groups and running a statistical significance test, we can determine whether discount‐driven orders truly differ in size—and adjust our coupon strategy (depth, targeting, eligibility) accordingly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e488594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prepare the two groups\n",
    "# “Used” vs. “Not Used” based on coupon_status\n",
    "used = sales_disc.loc[sales_disc['coupon_status']=='Used', 'total_amount']\n",
    "not_used = sales_disc.loc[sales_disc['coupon_status']!='Used', 'total_amount']\n",
    "\n",
    "# Calculate group stats\n",
    "mean_used     = used.mean()\n",
    "mean_not_used = not_used.mean()\n",
    "n_used        = used.size\n",
    "n_not_used    = not_used.size\n",
    "\n",
    "print(f\"Used coupon:      n = {n_used}, mean = {mean_used:.2f}\")\n",
    "print(f\"No coupon used:   n = {n_not_used}, mean = {mean_not_used:.2f}\")\n",
    "\n",
    "# Independent t-test (unequal variances)\n",
    "tstat, pval = ttest_ind(used, not_used, equal_var=False)\n",
    "print(f\"t-statistic = {tstat:.3f}, p-value = {pval:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc5af1",
   "metadata": {},
   "source": [
    "### 14.2 Results  \n",
    "\n",
    "| Group            | N      | Avg Transaction Value ($) |\n",
    "|------------------|--------|---------------------------|\n",
    "| **Used Coupon**      | 17,904 | 97.65                     |\n",
    "| **No Coupon Used**   | 35,020 | 99.35                     |\n",
    "\n",
    "- **t‐statistic:** -1.084  \n",
    "- **p‐value:** 0.2785  \n",
    "\n",
    "> With a p‐value > 0.05, the difference in average transaction value between coupon users and non‐users is **not** statistically significant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b6b55",
   "metadata": {},
   "source": [
    "## Question 15  \n",
    "**Do purchase behaviors (e.g., order frequency, order value) vary significantly across different demographic groups or pricing factors (e.g., delivery charges)?**  \n",
    "*Test for differences in purchase behavior across locations, tenure groups, and delivery‐charge tiers. How can these insights inform personalized marketing and pricing strategies?*\n",
    "\n",
    "### 15.1 Business Story & Context  \n",
    "> Customer value drivers—how often they buy and how much they spend—can differ by where they live, how long they’ve been with us, and even by delivery fees.  \n",
    "> By uncovering statistically significant differences, we can tailor promotions, pricing, and communication to each segment for maximum impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afa7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join customer demographics\n",
    "sales_demo = sales.merge(customers, on='customer_id')\n",
    "\n",
    "# Define tenure groups (in months) as proxy for “age”\n",
    "sales_demo['tenure_group'] = pd.cut(\n",
    "    sales_demo['tenure_months'],\n",
    "    bins=[0, 12, 36, np.inf],\n",
    "    labels=['<1yr','1-3yr','>3yr']\n",
    ")\n",
    "\n",
    "# Define delivery‐charge tiers\n",
    "sales_demo['delivery_tier'] = pd.cut(\n",
    "    sales_demo['delivery_charges'],\n",
    "    bins=[-np.inf, 5, 10, np.inf],\n",
    "    labels=['Low (≤5)','Mid (5-10)','High (>10)']\n",
    ")\n",
    "\n",
    "# Compute per-customer metrics\n",
    "cust_metrics = (\n",
    "    sales_demo\n",
    "    .groupby('customer_id')\n",
    "    .agg(\n",
    "        frequency=('transaction_id','nunique'),\n",
    "        avg_value =('total_amount','mean'),\n",
    "        location    =('location','first'),\n",
    "        tenure_group=('tenure_group','first'),\n",
    "        delivery_tier=('delivery_tier','first')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Summarize by group\n",
    "loc_summary = cust_metrics.groupby('location')[['frequency','avg_value']].describe().round(2)\n",
    "tenure_summary = cust_metrics.groupby('tenure_group', observed=False)[['frequency','avg_value']].describe().round(2)\n",
    "delivery_summary = cust_metrics.groupby('delivery_tier', observed=False)[['frequency','avg_value']].describe().round(2)\n",
    "\n",
    "print(\"Location Summary:\\n\", loc_summary)\n",
    "print(\"\\nTenure Summary:\\n\", tenure_summary)\n",
    "print(\"\\nDelivery-Tier Summary:\\n\", delivery_summary)\n",
    "\n",
    "# ANOVA tests\n",
    "f_loc, p_loc = f_oneway(*[g['avg_value'].values for _,g in cust_metrics.groupby('location')])\n",
    "f_tenure, p_tenure = f_oneway(*[g['avg_value'].values for _,g in cust_metrics.groupby('tenure_group', observed=False)])\n",
    "f_deliv, p_deliv = f_oneway(*[g['avg_value'].values for _,g in cust_metrics.groupby('delivery_tier', observed=False)])\n",
    "\n",
    "print(f\"\\nANOVA Avg Value by Location: F={f_loc:.2f}, p={p_loc:.3f}\")\n",
    "print(f\"ANOVA Avg Value by Tenure:   F={f_tenure:.2f}, p={p_tenure:.3f}\")\n",
    "print(f\"ANOVA Avg Value by Delivery: F={f_deliv:.2f}, p={p_deliv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec606c",
   "metadata": {},
   "source": [
    "### 15.2 Results  \n",
    "\n",
    "#### A. Mean Purchase Metrics by Group\n",
    "\n",
    "**By Location**  \n",
    "| Location       | Mean Frequency | Mean Avg Transaction Value ($) |\n",
    "|----------------|---------------:|-------------------------------:|\n",
    "| California     |          17.37 |                          95.93 |\n",
    "| Chicago        |          20.36 |                          99.04 |\n",
    "| New Jersey     |          15.36 |                          98.63 |\n",
    "| New York       |          17.24 |                          94.28 |\n",
    "| Washington DC  |          18.89 |                         112.29 |\n",
    "\n",
    "**By Tenure Group**  \n",
    "| Tenure Group | Mean Frequency | Mean Avg Transaction Value ($) |\n",
    "|--------------|---------------:|-------------------------------:|\n",
    "| <1yr         |          17.65 |                          98.33 |\n",
    "| 1–3yr        |          18.63 |                          95.69 |\n",
    "| >3yr         |          17.67 |                         100.53 |\n",
    "\n",
    "**By Delivery-Charge Tier**  \n",
    "| Delivery Tier | Mean Frequency | Mean Avg Transaction Value ($) |\n",
    "|---------------|---------------:|-------------------------------:|\n",
    "| Low (≤5)      |          31.00 |                         106.51 |\n",
    "| Mid (5–10)    |          17.99 |                          95.13 |\n",
    "| High (>10)    |          18.83 |                         110.00 |\n",
    "\n",
    "#### B. ANOVA Test Results (Avg Transaction Value)\n",
    "\n",
    "- **Location:** F = 1.59, p = 0.175 (no significant difference)  \n",
    "- **Tenure Group:** F = 0.91, p = 0.402 (no significant difference)  \n",
    "- **Delivery-Charge Tier:** F = 6.56, p = 0.001 (significant difference)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6847c4",
   "metadata": {},
   "source": [
    "## Question 16  \n",
    "**Does customer tenure impact purchase frequency?**  \n",
    "*Analyze the relationship between customer tenure and purchase frequency. How can this insight inform loyalty and engagement strategies?*\n",
    "\n",
    "### 16.1 Business Story & Context  \n",
    "> Customers who have been with us longer may purchase more (or less) often than newer customers.  \n",
    "> Understanding this relationship helps tailor loyalty programs, re-engagement campaigns, and onboarding tactics to each tenure cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize purchase frequency by tenure group\n",
    "freq_summary = cust_metrics.groupby('tenure_group', observed=False)['frequency'].describe().round(2)\n",
    "print(\"Frequency by Tenure Group:\\n\", freq_summary)\n",
    "\n",
    "# ANOVA test to see if mean frequency differs across tenure groups\n",
    "f_freq, p_freq = f_oneway(\n",
    "    *[grp['frequency'].values for _, grp in cust_metrics.groupby('tenure_group', observed=False)]\n",
    ")\n",
    "print(f\"\\nANOVA Frequency by Tenure: F={f_freq:.2f}, p={p_freq:.3f}\")\n",
    "\n",
    "freq_summary.to_csv('../eda_outputs/freq_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129616a",
   "metadata": {},
   "source": [
    "### 16.2 Results  \n",
    "\n",
    "**Purchase Frequency by Tenure Group**  \n",
    "| Tenure Group | Count | Mean Frequency | Std Dev | Min | 25% | 50% | 75% | Max  |\n",
    "|--------------|------:|---------------:|--------:|----:|----:|----:|----:|-----:|\n",
    "| <1yr         | 327   |          17.65 |   20.37 |  1.0|  5.0| 11.0| 24.5| 177.0|\n",
    "| 1–3yr        | 727   |          18.63 |   28.08 |  1.0|  5.0| 11.0| 23.5| 328.0|\n",
    "| >3yr         | 414   |          17.67 |   22.40 |  1.0|  5.0| 11.0| 23.0| 291.0|\n",
    "\n",
    "**ANOVA Test**  \n",
    "- F-statistic = 0.27  \n",
    "- p-value     = 0.760  \n",
    "\n",
    "> p-value > 0.05 ⇒ no statistically significant difference in purchase frequency across tenure cohorts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064af535",
   "metadata": {},
   "source": [
    "## Question 17  \n",
    "**Analyze the relationship between delivery charges and order behavior.**  \n",
    "*Are there opportunities to optimize delivery pricing to increase order quantities or revenue?*\n",
    "\n",
    "### 17.1 Business Story & Context  \n",
    "> Delivery fees can affect how much customers add to their cart (order value) and whether they complete an order at all (quantity ordered).  \n",
    "> By examining order behavior across low, mid, and high delivery‐charge tiers, and testing for significant differences, we can uncover pricing levers (e.g., free‐shipping thresholds or tiered fees) to boost basket size and overall revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define delivery-charge tiers on the transaction level\n",
    "sales['delivery_tier'] = pd.cut(\n",
    "    sales['delivery_charges'],\n",
    "    bins=[-np.inf, 5, 10, np.inf],\n",
    "    labels=['Low (≤$5)', 'Mid ($5-10)', 'High (>$10)']\n",
    ")\n",
    "\n",
    "# Compute order-level metrics by tier\n",
    "order_metrics = (\n",
    "    sales\n",
    "    .groupby('delivery_tier', observed=False)\n",
    "    .agg(\n",
    "        order_count     = ('transaction_id', 'count'),\n",
    "        avg_quantity    = ('quantity',       'mean'),\n",
    "        avg_order_value = ('total_amount',   'mean'),\n",
    "        total_revenue   = ('revenue',        'sum')\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# ANOVA to test differences in avg_order_value across tiers\n",
    "groups = [grp['total_amount'].values for _, grp in sales.groupby('delivery_tier', observed=False)]\n",
    "f_val, p_val = f_oneway(*groups)\n",
    "\n",
    "print(order_metrics)\n",
    "print(f\"\\nANOVA Avg Order Value by Delivery Tier: F = {f_val:.2f}, p = {p_val:.3f}\")\n",
    "\n",
    "order_metrics.to_csv('../eda_outputs/order_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f3612",
   "metadata": {},
   "source": [
    "### 17.2 Results  \n",
    "\n",
    "| Delivery Tier | Order Count | Avg Quantity | Avg Order Value ($) | Total Revenue ($)   |\n",
    "|---------------|------------:|-------------:|--------------------:|---------------------:|\n",
    "| Low (≤$5)     |         162 |          1.31|               120.66|              19,547.24|\n",
    "| Mid ($5–10)   |      43,017 |          3.13|                93.71|           3,764,379.19|\n",
    "| High (>$10)   |       9,745 |         10.57|               120.73|             886,868.19|\n",
    "\n",
    "**ANOVA on Avg Order Value by Delivery Tier**  \n",
    "- F-statistic = 106.52  \n",
    "- p-value     = 0.000 (significant at p<0.001)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d8b2a",
   "metadata": {},
   "source": [
    "## Question 18  \n",
    "**Evaluate how taxes and delivery charges influence customer spending behavior.**  \n",
    "*Are there opportunities to adjust pricing strategies to improve customer satisfaction and revenue?*\n",
    "\n",
    "### 18.1 Business Story & Context  \n",
    "> Both product-level GST rates and delivery fees add to the final price customers pay.  \n",
    "> Understanding how different tax brackets and delivery-charge tiers affect basket size and order value helps optimize pricing (thresholds, bundling, and promotions) to balance top-line revenue and customer satisfaction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sales with GST rates\n",
    "sales_tax = sales.merge(tax, on='product_category')\n",
    "\n",
    "# Compute tax amount and total spend including tax\n",
    "sales_tax['tax_amt'] = sales_tax['revenue'] * sales_tax['gst']\n",
    "sales_tax['spend_inc_tax'] = sales_tax['total_amount'] + sales_tax['tax_amt']\n",
    "\n",
    "# Summarize spend_inc_tax by GST rate\n",
    "gst_summary = (\n",
    "    sales_tax\n",
    "    .groupby('gst')['spend_inc_tax']\n",
    "    .agg(['count','mean','std'])\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# ANOVA test across GST groups\n",
    "f_tax, p_tax = f_oneway(\n",
    "    *[grp['spend_inc_tax'].values for _, grp in sales_tax.groupby('gst')]\n",
    ")\n",
    "\n",
    "# Correlation between delivery fee and spend_inc_tax\n",
    "corr = sales_tax[['delivery_charges','spend_inc_tax']].corr().iloc[0,1]\n",
    "\n",
    "print(\"GST Summary:\\n\", gst_summary)\n",
    "print(f\"\\nANOVA by GST: F = {f_tax:.2f}, p = {p_tax:.3f}\")\n",
    "print(f\"\\nCorrelation between delivery charges and spend_inc_tax: {corr:.3f}\")\n",
    "\n",
    "order_metrics.to_csv('../eda_outputs/order_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e4089",
   "metadata": {},
   "source": [
    "### 18.2 Results  \n",
    "\n",
    "**A. Spend Including Tax by GST Rate**  \n",
    "| GST Rate | Count | Mean Spend ($) | Std Dev ($) |\n",
    "|---------:|------:|---------------:|------------:|\n",
    "| 0.05     |  4,145|         188.98 |      372.92 |\n",
    "| 0.10     | 21,314|         160.88 |      151.24 |\n",
    "| 0.12     |    122|          59.43 |       97.61 |\n",
    "| 0.18     | 27,343|          55.68 |      140.19 |\n",
    "\n",
    "- **ANOVA by GST:** F = 1782.59, p < 0.001 (significant differences in spend among GST brackets)  \n",
    "- **Correlation (delivery fee vs. spend incl. tax):** r = 0.176 (weak positive relationship)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b144bf",
   "metadata": {},
   "source": [
    "## Question 19  \n",
    "**Identify seasonal trends in sales by category and location.**  \n",
    "*How can the company prepare for peak and off‐peak seasons to maximize revenue?*\n",
    "\n",
    "### 19.1 Business Story & Context  \n",
    "> Different product categories and regions often experience their own “seasons” of high and low demand.  \n",
    "> By mapping monthly revenue patterns by category and by location, we can anticipate inventory needs, staffing, and marketing budgets—ensuring we’re fully stocked and promoted when demand peaks, and optimizing costs in slower months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join sales with customer location\n",
    "sales_loc = sales.merge(customers[['customer_id','location']], on='customer_id')\n",
    "\n",
    "# Aggregate monthly revenue by category\n",
    "category_season = (\n",
    "    sales_loc\n",
    "    .groupby(['transaction_month','product_category'])['revenue']\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Aggregate monthly revenue by location\n",
    "location_season = (\n",
    "    sales_loc\n",
    "    .groupby(['transaction_month','location'])['revenue']\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Display the first few rows of each\n",
    "print(\"Category Seasonality (first 6 months):\\n\", category_season.head(6))\n",
    "print(\"\\nLocation Seasonality (first 6 months):\\n\", location_season.head(6))\n",
    "\n",
    "category_season.to_csv('../eda_outputs/category_season.csv', index=False)\n",
    "location_season.to_csv('../eda_outputs/location_season.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172aadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "\n",
    "# Plot each category’s monthly revenue\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cat in category_season.columns:\n",
    "    plt.plot(category_season.index.astype(str), category_season[cat], marker='o', label=cat)\n",
    "plt.title(\"Monthly Revenue by Product Category\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/category_season.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot each location’s monthly revenue\n",
    "plt.figure(figsize=(10, 6))\n",
    "for loc in location_season.columns:\n",
    "    plt.plot(location_season.index.astype(str), location_season[loc], marker='o', label=loc)\n",
    "plt.title(\"Monthly Revenue by Location\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/location_season.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7f9f8",
   "metadata": {},
   "source": [
    "### 19.2 Results  \n",
    "\n",
    "#### A. Category Seasonality (First 6 Months)\n",
    "\n",
    "| Month    | Apparel   | Bags      | Drinkware | Nest-USA   | Office   |\n",
    "|----------|----------:|----------:|----------:|-----------:|---------:|\n",
    "| 2019-01  |  38,300.87|  10,903.63|  14,599.09|   284,362.08|  27,309.50|\n",
    "| 2019-02  |  37,990.09|  17,969.55|  14,334.22|   196,182.19|  20,994.91|\n",
    "| 2019-03  |  59,059.02|  14,045.65|  21,228.20|   199,700.00|  27,783.12|\n",
    "| 2019-04  |  88,138.14|  11,385.03|  27,090.43|   182,193.00|  36,507.38|\n",
    "| 2019-05  |  58,850.90|   9,962.99|  16,424.25|   173,534.00|  23,022.42|\n",
    "| 2019-06  |  45,941.01|  12,867.37|  17,622.04|   195,413.00|  22,718.12|\n",
    "\n",
    "#### B. Location Seasonality (First 6 Months)\n",
    "\n",
    "| Month    | California | Chicago  | New Jersey | New York  | Washington DC |\n",
    "|----------|-----------:|---------:|-----------:|----------:|--------------:|\n",
    "| 2019-01  | 150,241.63 |109,911.74|   31,475.72| 78,217.28 |      33,778.21|\n",
    "| 2019-02  |  89,727.46 |108,031.09|   30,266.50| 44,748.86 |      38,045.89|\n",
    "| 2019-03  |  99,243.75 |118,365.41|   19,393.74| 97,026.06 |      15,579.13|\n",
    "| 2019-04  | 121,139.09 |152,811.80|   44,989.45| 63,181.57 |      19,496.51|\n",
    "| 2019-05  |  86,602.49 |109,277.26|   28,295.03| 77,345.24 |       6,243.40|\n",
    "| 2019-06  | 100,427.83 |100,742.75|   40,006.89| 68,613.44 |      11,290.47|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5b8ff",
   "metadata": {},
   "source": [
    "## Question 20  \n",
    "**Analyze daily sales trends to identify high-performing and low-performing days.**  \n",
    "*What strategies can be implemented to boost sales on slower days?*\n",
    "\n",
    "### 20.1 Business Story & Context  \n",
    "> Identifying which days of the week (and specific dates) generate the most and least revenue enables smarter staffing, inventory planning, and timing of promotional campaigns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6823e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by weekday\n",
    "sales['weekday'] = sales['transaction_date'].dt.day_name()\n",
    "weekday_summary = (\n",
    "    sales\n",
    "    .groupby('weekday')['revenue']\n",
    "    .agg(count='count', total='sum', avg='mean')\n",
    "    .reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "    .round(2)\n",
    ")\n",
    "print(\"Weekday Summary:\\n\", weekday_summary)\n",
    "\n",
    "# daily time series\n",
    "daily_ts = sales.groupby('transaction_date')['revenue'].sum().reset_index()\n",
    "print(\"Daily Revenue Time Series (first 5 rows):\\n\", daily_ts.head())\n",
    "\n",
    "weekday_summary.to_csv('../eda_outputs/weekday_summary.csv', index=False)\n",
    "daily_ts.to_csv('../eda_outputs/daily_ts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "# Bar chart: Avg revenue by weekday\n",
    "plt.figure(figsize=(8,5))\n",
    "weekday_summary['avg'].plot(kind='bar')\n",
    "plt.title(\"Average Revenue by Weekday\")\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Avg Revenue ($)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/weekday_summary.png')\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Line chart: Daily revenue over time\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(daily_ts['transaction_date'], daily_ts['revenue'])\n",
    "plt.title(\"Daily Revenue Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Revenue ($)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/daily_ts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e8465",
   "metadata": {},
   "source": [
    "### 20.2 – Results  \n",
    "**Weekday Summary**  \n",
    "| Weekday   | # Transactions | Total Revenue ($) | Avg. Revenue per Day ($) |\n",
    "|-----------|----------------|-------------------|--------------------------:|\n",
    "| Monday    | 4 464          | 365 626.90        | 81.91                     |\n",
    "| Tuesday   | 4 611          | 396 819.65        | 86.06                     |\n",
    "| Wednesday | 8 887          | 826 622.00        | 93.01                     |\n",
    "| Thursday  | 9 000          | 840 433.85        | 93.38                     |\n",
    "| Friday    | 9 266          | 872 004.86        | 94.11                     |\n",
    "| Saturday  | 8 177          | 673 068.03        | 82.31                     |\n",
    "| Sunday    | 8 519          | 696 219.33        | 81.73                     |\n",
    "\n",
    "- **Highest average daily revenue** occurs on **Friday ($94.11 K)** and **Thursday ($93.38 K)**.  \n",
    "- **Lowest average** on **Sunday ($81.73 K)** and **Monday ($81.91 K)**.  \n",
    "\n",
    "**Daily Time Series**  \n",
    "- The line chart shows sharp spikes on certain dates (likely major promotions or product launches) interspersed with a clear “sawtooth” weekly pattern.  \n",
    "- Revenue gradually trends upward toward year-end with pronounced peaks.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaler-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
